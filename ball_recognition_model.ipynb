{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"ball_recognition_model.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["Making more data by cutting left upper/right bottom corner and then also flipping horizontally both pictures - it gives 4 new pictures from 1"],"metadata":{"id":"8NcV4NRkPhyw"}},{"cell_type":"code","source":["#@title\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# no_train_images = len(train_images)\n","# train_xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","# from google.colab.patches import cv2_imshow\n","\n","# i=0\n","# for img_path in train_images:\n","#   xml_path = img_path[:-4] + \".xml\"\n","#   if xml_path not in train_xmls:\n","#     print(\"missing xml\" + xml_path)\n","#     continue\n","#   img = cv2.imread(img_path)\n","\n","#   root = ET.parse(xml_path).getroot()\n","#   x1 = int(root.find('object/bndbox/xmin').text)\n","#   y1 = int(root.find('object/bndbox/ymin').text)\n","#   x2 = int(root.find('object/bndbox/xmax').text)\n","#   y2 = int(root.find('object/bndbox/ymax').text)\n","#   train_bboxes = [x1, y1, x2, y2]\n","\n","#   im = img[270:, 480:]\n","#   x_min, y_min, x_max, y_max = train_bboxes[0]-480, train_bboxes[1]-270, train_bboxes[2]-480, train_bboxes[3]-270\n","\n","#   if not (x_min < 0 or y_min < 0):\n","#     cv2.imwrite('/content/drive/MyDrive/images/cropped/'+'up_left_corner_cut_'+str(i)+'.jpg', im)\n","\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/cropped/'+'up_left_corner_cut_'+str(i)+'.xml')\n","#     xml = ET.parse('/content/drive/MyDrive/images/cropped/up_left_corner_cut_'+str(i)+'.xml')\n","#     root = xml.getroot()\n","#     root.find('object/bndbox/xmin').text = str(x_min)\n","#     root.find('object/bndbox/ymin').text = str(y_min)\n","#     root.find('object/bndbox/xmax').text = str(x_max)\n","#     root.find('object/bndbox/ymax').text = str(y_max)\n","#     xml.write('/content/drive/MyDrive/images/cropped/up_left_corner_cut_'+str(i)+'.xml')\n","\n","#     im_mirror = cv2.flip(im, 1)\n","#     cv2.imwrite('/content/drive/MyDrive/images/cropped/'+'flipped1_'+str(i)+'.jpg', im_mirror)\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/cropped/'+'flipped1_'+str(i)+'.xml')\n","#     xml = ET.parse('/content/drive/MyDrive/images/cropped/'+'flipped1_'+str(i)+'.xml')\n","#     root = xml.getroot()\n","#     temp = 1440-x_min\n","#     x_min = 1440-x_max\n","#     x_max = temp\n","#     root.find('object/bndbox/xmin').text = str(x_min)\n","#     root.find('object/bndbox/ymin').text = str(y_min)\n","#     root.find('object/bndbox/xmax').text = str(x_max)\n","#     root.find('object/bndbox/ymax').text = str(y_max)\n","#     xml.write('/content/drive/MyDrive/images/cropped/flipped1_'+str(i)+'.xml')\n","\n","#   im1 = img[:-270, :-480]\n","#   x_min, y_min, x_max, y_max = train_bboxes[0], train_bboxes[1], train_bboxes[2], train_bboxes[3]\n","#   if not (y_max > 810 or x_max > 1440):\n","#     cv2.imwrite('/content/drive/MyDrive/images/cropped/'+'down_right_corner_cut_'+str(i)+'.jpg', im1)\n","\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/cropped/'+'down_right_corner_cut_'+str(i)+'.xml')\n","#     xml = ET.parse('/content/drive/MyDrive/images/cropped/down_right_corner_cut_'+str(i)+'.xml')\n","#     root = xml.getroot()\n","#     root.find('object/bndbox/xmin').text = str(x_min)\n","#     root.find('object/bndbox/ymin').text = str(y_min)\n","#     root.find('object/bndbox/xmax').text = str(x_max)\n","#     root.find('object/bndbox/ymax').text = str(y_max)\n","#     xml.write('/content/drive/MyDrive/images/cropped/down_right_corner_cut_'+str(i)+'.xml')\n","\n","#     im_mirror1 = cv2.flip(im1, 1)\n","#     cv2.imwrite('/content/drive/MyDrive/images/cropped/'+'flipped2_'+str(i)+'.jpg', im_mirror1)\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/cropped/'+'flipped2_'+str(i)+'.xml')\n","#     xml = ET.parse('/content/drive/MyDrive/images/cropped/'+'flipped2_'+str(i)+'.xml')\n","#     root = xml.getroot()\n","#     temp = 1440-x_min\n","#     x_min = 1440-x_max\n","#     x_max = temp\n","#     root.find('object/bndbox/xmin').text = str(x_min)\n","#     root.find('object/bndbox/ymin').text = str(y_min)\n","#     root.find('object/bndbox/xmax').text = str(x_max)\n","#     root.find('object/bndbox/ymax').text = str(y_max)\n","#     xml.write('/content/drive/MyDrive/images/cropped/flipped2_'+str(i)+'.xml')\n","#   i+=1"],"metadata":{"id":"MCWbve4CE6WT","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Showing images from selected folder folder"],"metadata":{"id":"JpMQ9lQyPc3o"}},{"cell_type":"code","source":["#@title\n","# cropped_images = list(glob.glob('/content/drive/MyDrive/images/CandB/*.jpg'))\n","# cropped_xmls = list(glob.glob('/content/drive/MyDrive/images/CandB/*.xml'))\n","\n","# for img_path in cropped_images:\n","#   xml_path = img_path[:-4] + \".xml\"\n","#   if xml_path not in cropped_xmls:\n","#     print(\"missing xml\" + xml_path)\n","#     continue\n","#   image_open = open(img_path, 'rb')\n","#   read_image = image_open.read()\n","#   image_decode = tf.image.decode_jpeg(read_image)\n","#   test_image_array = tf.keras.preprocessing.image.img_to_array(image_decode)\n","#   img = test_image_array/255.\n","\n","#   root = ET.parse(xml_path).getroot()\n","#   x1 = int(root.find('object/bndbox/xmin').text)\n","#   y1 = int(root.find('object/bndbox/ymin').text)\n","#   x2 = int(root.find('object/bndbox/xmax').text)\n","#   y2 = int(root.find('object/bndbox/ymax').text)\n","#   train_bboxes = [x1, y1, x2, y2]\n","\n","#   tensor = img*255.\n","#   arr = np.array(tensor, dtype=np.uint8)\n","#   sh_im = Image.fromarray(arr)\n","#   shape = ((train_bboxes[0], train_bboxes[1]), (train_bboxes[2], train_bboxes[3]))\n","#   img_draw = ImageDraw.Draw(sh_im)\n","#   img_draw.rectangle(shape, outline =\"red\", width=3)\n","#   display(sh_im)"],"metadata":{"id":"9KagYz1p2to5","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Making more data by changing contrast"],"metadata":{"id":"cpseQAFpMjXr"}},{"cell_type":"code","source":["#@title\n","# cropped_images = list(glob.glob('/content/drive/MyDrive/images/cropped/*.jpg'))\n","# no_cropped_images = len(cropped_images)\n","# cropped_xmls = list(glob.glob('/content/drive/MyDrive/images/cropped/*.xml'))\n","\n","# i=0\n","# for j in range(1, 9, 1):\n","#   for img_path in cropped_images:\n","#     xml_path = img_path[:-4] + \".xml\"\n","#     if xml_path not in cropped_xmls:\n","#       print(\"missing xml\" + xml_path)\n","#       continue\n","#     image_open = open(img_path, 'rb')\n","#     read_image = image_open.read()\n","#     image_decode = tf.image.decode_jpeg(read_image)\n","#     tensor = tf.image.adjust_contrast(image_decode, j/10)\n","#     arr = np.array(tensor, dtype=np.uint8)\n","#     path_temp = img_path[:img_path.rfind('/')-7] + 'contrastAndBrightness/'\n","#     tf.keras.utils.save_img(path_temp+'contrast_'+str(i)+'.jpg', arr)\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/contrastAndBrightness/'+'contrast_'+str(i)+'.xml')\n","#     if i%400 == 0:\n","#       print(str(100*i/(no_cropped_images*8))+'%')\n","#     i+=1"],"metadata":{"id":"JGtaDMAAGd0h","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Making more data by changing brightness"],"metadata":{"id":"H3yTXYfxPVCa"}},{"cell_type":"code","source":["#@title\n","# cropped_images = list(glob.glob('/content/drive/MyDrive/images/cropped/*.jpg'))\n","# no_cropped_images = len(cropped_images)\n","# cropped_xmls = list(glob.glob('/content/drive/MyDrive/images/cropped/*.xml'))\n","\n","# i=0\n","# for j in range(-5, 5, 1):\n","#   for img_path in cropped_images:\n","#     xml_path = img_path[:-4] + \".xml\"\n","#     if xml_path not in cropped_xmls:\n","#       print(\"missing xml\" + xml_path)\n","#       continue\n","#     image_open = open(img_path, 'rb')\n","#     read_image = image_open.read()\n","#     image_decode = tf.image.decode_jpeg(read_image)\n","#     tensor = tf.image.adjust_brightness(image_decode, j/10)\n","#     arr = np.array(tensor, dtype=np.uint8)\n","#     path_temp = img_path[:img_path.rfind('/')-7] + 'contrastAndBrightness/'\n","#     tf.keras.utils.save_img(path_temp+'brightness_'+str(i)+'.jpg', arr)\n","#     os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/contrastAndBrightness/'+'brightness_'+str(i)+'.xml')\n","#     if i%400 == 0:\n","#       print(str(100*i/(no_cropped_images*8))+'%')\n","#     i+=1"],"metadata":{"id":"zy69TCLnPURx","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Moving 200 pictures from train to validation\n","\n"],"metadata":{"id":"QiNfEeg35aDc"}},{"cell_type":"code","source":["#@title\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","\n","# for ele in train_images[-200:]:\n","#   xml_path = ele[:-4] + \".xml\"\n","#   os.system(\"mv \" + ele + \" /content/drive/MyDrive/images/validation/\")\n","#   os.system(\"mv \" + xml_path + \" /content/drive/MyDrive/images/validation/\")"],"metadata":{"id":"n3_QFvry12GX","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Deleting pictures without xml's in train folder\n","(assuming object is on picture)"],"metadata":{"id":"z86KT6DgDdrZ"}},{"cell_type":"code","source":["#@title\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","# for img_path in train_images:\n","#   xml_path = img_path[:-4] + \".xml\"\n","#   if xml_path not in xmls:\n","#     os.remove(img_path)"],"metadata":{"id":"V5Jb8DijBWhx","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Deleting xml's in without pictures train folder (needed after deleting bad pictures)"],"metadata":{"id":"PEPSKQWtTNul"}},{"cell_type":"code","source":["#@title\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","# for xml_path in xmls:\n","#   img_path = img_path[:-4] + \".jpg\"\n","#   if img_path not in train_images:\n","#     os.remove(xml_path)"],"metadata":{"id":"XYvfnJKUTMic","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Drawing box on an image"],"metadata":{"id":"pUgUEu_Vh29P"}},{"cell_type":"code","source":["#@title\n","# from PIL import ImageDraw, Image\n","\n","# test_image_path = '/content/drive/MyDrive/images/frame225.jpg'\n","# image_open = open(test_image_path, 'rb')\n","# read_image = image_open.read()\n","# image_decode = tf.image.decode_jpeg(read_image)\n","# test_image_resized = tf.image.resize(image_decode, [540, 960])\n","# test_image_array = tf.keras.preprocessing.image.img_to_array(test_image_resized)\n","# img = test_image_array/255.\n","\n","# tensor = img*255.\n","# arr = np.array(tensor, dtype=np.uint8)\n","# # print(arr.shape)\n","# sh_im = Image.fromarray(arr)\n","# shape = ((1482//2, 342//2),  (1563//2, 428//2))\n","# img_draw = ImageDraw.Draw(sh_im)\n","# img_draw.rectangle(shape, outline =\"red\")\n","# display(sh_im)"],"metadata":{"id":"eGJ-Dnt4QSqD","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["TPU activation, but GPU is way better"],"metadata":{"id":"XfV1D2TMj3cW"}},{"cell_type":"code","source":["#@title\n","# resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='grpc://' + os.environ['COLAB_TPU_ADDR'])\n","# tf.config.experimental_connect_to_cluster(resolver)\n","# tf.tpu.experimental.initialize_tpu_system(resolver)"],"metadata":{"id":"yq9sD5TbjvTb","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Making more pictures by adding noise"],"metadata":{"id":"6GSHXQ1tBzjb"}},{"cell_type":"code","source":["#@title\n","# from google.colab.patches import cv2_imshow\n","# from skimage.util import random_noise\n","\n","\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# train_xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","# i = 0\n","# for img_path in train_images:\n","#   xml_path = img_path[:-4] + \".xml\"\n","#   if xml_path not in train_xmls:\n","#     print(\"missing xml\" + xml_path)\n","#     continue\n","#   img = cv2.imread(img_path)\n","\n","#   noise_img1 = random_noise(img, mode='pepper')\n","#   noise_img1 = np.array(255*noise_img1, dtype = 'uint8')\n","#   noise_img2 = random_noise(img, mode='gaussian')\n","#   noise_img2 = np.array(255*noise_img2, dtype = 'uint8')\n","#   noise_img3 = random_noise(img, mode='s&p', amount=0.1)\n","#   noise_img3 = np.array(255*noise_img3, dtype = 'uint8')\n","#   cv2.imwrite('/content/drive/MyDrive/images/noise/'+'noise_img_'+str(i)+'.jpg', noise_img1)\n","#   cv2.imwrite('/content/drive/MyDrive/images/noise/'+'noise_img_'+str(i+1)+'.jpg', noise_img2)\n","#   cv2.imwrite('/content/drive/MyDrive/images/noise/'+'noise_img_'+str(i+2)+'.jpg', noise_img3)\n","#   os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/noise/'+'noise_img_'+str(i)+'.xml')\n","#   os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/noise/'+'noise_img_'+str(i+1)+'.xml')\n","#   os.system('cp ' + xml_path + ' /content/drive/MyDrive/images/noise/'+'noise_img_'+str(i+2)+'.xml')\n","#   i+=3"],"metadata":{"id":"-DHWq4ByByxF","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Loading imgs"],"metadata":{"id":"TVtaJJQUxI7B"}},{"cell_type":"code","source":["#@title\n","train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))[:100]\n","no_train_images = len(train_images)\n","train_xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","\n","train_imgs = np.zeros((no_train_images, 270, 480, 3), dtype=np.float16)\n","train_bboxes = np.zeros((no_train_images, 4), dtype=np.int16)\n","\n","i = 0\n","for img_path in train_images:\n","  xml_path = img_path[:-4] + \".xml\"\n","  if xml_path not in train_xmls:\n","    print(\"missing xml\" + xml_path)\n","    continue\n","  image_open = open(img_path, 'rb')\n","  read_image = image_open.read()\n","  image_decode = tf.image.decode_jpeg(read_image)\n","  if (image_decode.shape[0] == 1080):\n","    DIVIDER = 4\n","  else:\n","    DIVIDER = 3\n","  test_image_resized = tf.image.resize(image_decode, [270, 480])\n","  test_image_array = tf.keras.preprocessing.image.img_to_array(test_image_resized)\n","  img = test_image_array/255.\n","  train_imgs[i] = img\n","\n","  root = ET.parse(xml_path).getroot()\n","  x1 = int(root.find('object/bndbox/xmin').text)\n","  y1 = int(root.find('object/bndbox/ymin').text)\n","  x2 = int(root.find('object/bndbox/xmax').text)\n","  y2 = int(root.find('object/bndbox/ymax').text)\n","  train_bboxes[i] = [x1//DIVIDER, y1//DIVIDER, x2//DIVIDER, y2//DIVIDER]\n","  if i%100 == 0:\n","    print(str(100*i/no_train_images)+'%')\n","\n","# Showing images with boxes\n","\n","  # if i%400 == 0:\n","  # tensor = train_imgs[i]*255.\n","  # arr = np.array(tensor, dtype=np.uint8)\n","  # sh_im = Image.fromarray(arr)\n","  # shape = ((train_bboxes[i][0], train_bboxes[i][1]), (train_bboxes[i][2], train_bboxes[i][3]))\n","  # img_draw = ImageDraw.Draw(sh_im)\n","  # img_draw.rectangle(shape, outline =\"red\", width=3)\n","  # display(sh_im)\n","\n","  i+=1\n","\n","validation_images = list(glob.glob('/content/drive/MyDrive/images/validation/*.jpg'))[:20]\n","no_validation_images = len(validation_images)\n","validation_xmls = list(glob.glob('/content/drive/MyDrive/images/validation/*.xml'))\n","\n","validation_imgs = np.zeros((no_validation_images, 270, 480, 3), dtype=np.float16)\n","validation_bboxes = np.zeros((no_validation_images, 4), dtype=np.int16)\n","\n","i = 0\n","for img_path in validation_images:\n","  xml_path = img_path[:-4] + \".xml\"\n","  if xml_path not in validation_xmls:\n","    print(\"missing xml\" + xml_path)\n","    continue\n","  image_open = open(img_path, 'rb')\n","  read_image = image_open.read()\n","  image_decode = tf.image.decode_jpeg(read_image)\n","  if (image_decode.shape[0] == 1080):\n","    DIVIDER = 4\n","  else:\n","    DIVIDER = 3\n","  test_image_resized = tf.image.resize(image_decode, [270, 480])\n","  test_image_array = tf.keras.preprocessing.image.img_to_array(test_image_resized)\n","  img = test_image_array/255.\n","  validation_imgs[i] = img\n","\n","  root = ET.parse(xml_path).getroot()\n","  x1 = int(root.find('object/bndbox/xmin').text)\n","  y1 = int(root.find('object/bndbox/ymin').text)\n","  x2 = int(root.find('object/bndbox/xmax').text)\n","  y2 = int(root.find('object/bndbox/ymax').text)\n","  validation_bboxes[i] = [x1//DIVIDER, y1//DIVIDER, x2//DIVIDER, y2//DIVIDER]\n","\n","  # if i%5==0:\n","  #   tensor = validation_imgs[i]*255.\n","  #   arr = np.array(tensor, dtype=np.uint8)\n","  #   sh_im = Image.fromarray(arr)\n","  #   shape = ((validation_bboxes[i][0], validation_bboxes[i][1]), (validation_bboxes[i][2], validation_bboxes[i][3]))\n","  #   img_draw = ImageDraw.Draw(sh_im)\n","  #   img_draw.rectangle(shape, outline =\"red\", width=3)\n","  #   display(sh_im)\n","\n","  i+=1\n","\n","train_images = []\n","train_xmls = []\n","validation_images = []\n","validation_xmls = []"],"metadata":{"id":"X_v67e3A8ZWI","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Model"],"metadata":{"id":"uvIRqZKXxG_Q"}},{"cell_type":"code","source":["#@title\n","# model = keras.Sequential()\n","# model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(270,480,3)))\n","# model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","# model.add(layers.MaxPooling2D(pool_size=2))\n","# model.add(layers.Dropout(0.2))\n","# model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","# model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","# model.add(layers.MaxPooling2D(pool_size=2))\n","# model.add(layers.Dropout(0.2))\n","# model.add(layers.Conv2D(filters=24, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","# model.add(layers.Conv2D(filters=24, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","# model.add(layers.MaxPooling2D(pool_size=2))\n","# model.add(layers.Dropout(0.2))\n","# model.add(layers.Flatten())\n","# model.add(layers.Dense(16, activation=\"relu\")) \n","# model.add(layers.Dense(16, activation=\"relu\"))\n","# model.add(layers.Dense(4))\n","\n","# model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=tfa.losses.GIoULoss(), metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","# #print(model.summary())\n","\n","# history = model.fit(x=train_imgs, y=train_bboxes, batch_size=1, epochs=15, validation_data=(validation_imgs, validation_bboxes), shuffle=True)"],"metadata":{"id":"U2Yzoc0LraWE","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Connect drive"],"metadata":{"id":"uNhY_E04oV0R"}},{"cell_type":"code","source":["#@title\n","# from google.colab import drive\n","# drive.mount('/content/drive')"],"metadata":{"cellView":"form","id":"gNoFu1VFoZDu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Scale images to (270,480) and save"],"metadata":{"id":"k56n2eHi9qje"}},{"cell_type":"code","source":["#@title\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/validation/*.jpg'))\n","# no_train_images = len(train_images)\n","# train_xmls = list(glob.glob('/content/drive/MyDrive/images/validation/*.xml'))\n","\n","# i = 0\n","# for img_path in train_images:\n","#   xml_path = img_path[:-4] + \".xml\"\n","#   if xml_path not in train_xmls:\n","#     print(\"missing xml\" + xml_path)\n","#     continue\n","#   image_open = open(img_path, 'rb')\n","#   read_image = image_open.read()\n","#   image_decode = tf.image.decode_jpeg(read_image)\n","#   if (image_decode.shape[0] == 1080):\n","#     DIVIDER = 4\n","#   else:\n","#     DIVIDER = 3\n","#   test_image_resized = tf.image.resize(image_decode, [270, 480])\n","#   test_image_array = tf.keras.preprocessing.image.img_to_array(test_image_resized)\n","#   img = test_image_array\n","#   tf.keras.utils.save_img('/content/drive/MyDrive/images/Validation/'+img_path[img_path.rfind('/'):], img)\n","\n","#   xml = ET.parse(xml_path)\n","#   root = xml.getroot()\n","#   x1 = int(root.find('object/bndbox/xmin').text)\n","#   y1 = int(root.find('object/bndbox/ymin').text)\n","#   x2 = int(root.find('object/bndbox/xmax').text)\n","#   y2 = int(root.find('object/bndbox/ymax').text)\n","#   train_bboxes = [x1//DIVIDER, y1//DIVIDER, x2//DIVIDER, y2//DIVIDER]\n","\n","#   root.find('object/bndbox/xmin').text = str(train_bboxes[0])\n","#   root.find('object/bndbox/ymin').text = str(train_bboxes[1])\n","#   root.find('object/bndbox/xmax').text = str(train_bboxes[2])\n","#   root.find('object/bndbox/ymax').text = str(train_bboxes[3])\n","#   xml.write('/content/drive/MyDrive/images/Validation/'+xml_path[xml_path.rfind('/'):])\n","\n","#   if i%100 == 0:\n","#     print(str(100*i/no_train_images)+'%')\n","\n","#   i+=1"],"metadata":{"id":"R3SKhpos9rNc","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Showing number of pictures\n"],"metadata":{"id":"xtPVU7SlBKsX"}},{"cell_type":"code","source":["#@title\n","# print(\"Train_images:\")\n","# train_images = list(glob.glob('/content/drive/MyDrive/images/train/*.jpg'))\n","# print(len(train_images))\n","# train_xmls = list(glob.glob('/content/drive/MyDrive/images/train/*.xml'))\n","# print(len(train_xmls))\n","# print()\n","# print(\"Validation_images:\")\n","# validation_images = list(glob.glob('/content/drive/MyDrive/images/validation/*.jpg')) + list(glob.glob('/content/drive/MyDrive/images/validation_cropped/*.jpg'))\n","# print(len(validation_images))\n","# validation_xmls = list(glob.glob('/content/drive/MyDrive/images/validation/*.xml')) + list(glob.glob('/content/drive/MyDrive/images/validation_cropped/*.xml'))\n","# print(len(validation_xmls))\n","# print()\n","# print(\"Cropped_images:\")\n","# cropped_images = list(glob.glob('/content/drive/MyDrive/images/cropped/*.jpg'))\n","# print(len(cropped_images))\n","# cropped_xmls = list(glob.glob('/content/drive/MyDrive/images/cropped/*.xml'))\n","# print(len(cropped_xmls))\n","# print()\n","# print(\"ContrastAndBrightness_images:\")\n","# c_and_b_images = list(glob.glob('/content/drive/MyDrive/images/contrastAndBrightness/*.jpg'))\n","# print(len(c_and_b_images))\n","# c_and_b_xmls = list(glob.glob('/content/drive/MyDrive/images/contrastAndBrightness/*.xml'))\n","# print(len(c_and_b_xmls))\n","# print()"],"metadata":{"id":"1_cU2NrTxweQ","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["All imports required"],"metadata":{"id":"gfYuTHXghLzJ"}},{"cell_type":"code","source":["import glob\n","import tensorflow as tf\n","import keras\n","from keras import layers\n","import numpy as np\n","from xml.etree import ElementTree as ET\n","from PIL import ImageDraw, Image\n","import matplotlib.pyplot as plt\n","from google.colab import drive\n","import cv2\n","import os\n","!pip install -q tfds-nightly\n","import tensorflow_datasets as tfds\n","!pip install keras-tuner --upgrade\n","import keras_tuner as kt\n","import gdown"],"metadata":{"id":"yDmyw1VMhGVk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Download required files"],"metadata":{"id":"s-TnKVvu5vyE"}},{"cell_type":"code","source":["!gdown --fuzzy https://drive.google.com/file/d/1ZbBsljRwlPSVCBWa_nJRJNwoblIEKDQE/view?usp=sharing\n","!tar -xzf /content/CandB.tar.gz\n","!gdown --fuzzy https://drive.google.com/file/d/1y8djbAYlOxd2TWGxlWUjBRG1HQ4WaPUj/view?usp=sharing\n","!tar -xzf /content/datas.tar.gz\n","!gdown --fuzzy https://drive.google.com/file/d/1aY_CLPxOBpAFm9zTekepMoBJ5qJvRolv/view?usp=sharing\n","!tar -xzf /content/Validation.tar.gz\n","!gdown --fuzzy https://drive.google.com/file/d/1BU-QcU4Ew_8YhAbqBulo4RXLsrMDxzZR/view?usp=sharing\n","!tar -xzf /content/validatas.tar.gz"],"metadata":{"id":"xdE-efpZUuC6"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Load dataset"],"metadata":{"id":"7YqbgQNJ9Vpf"}},{"cell_type":"code","source":["def normalize_img(image, label):\n","  return tf.cast(image, tf.float32) / 255., label"],"metadata":{"id":"nS58IaclWXuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import datas\n","ds_train = tfds.load('datas', split=tfds.Split.TRAIN, as_supervised=True, shuffle_files=True)\n","\n","ds_train = ds_train.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","ds_train = ds_train.shuffle(buffer_size=1000)\n","ds_train = ds_train.batch(32)\n","ds_train = ds_train.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"kyDftyqDst8u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import validatas\n","ds_validate = tfds.load('validatas', split=tfds.Split.TRAIN, as_supervised=True, shuffle_files=True)\n","\n","ds_validate = ds_validate.map(normalize_img, num_parallel_calls=tf.data.AUTOTUNE)\n","ds_validate = ds_validate.shuffle(buffer_size=1000)\n","ds_validate = ds_validate.batch(32)\n","ds_validate = ds_validate.prefetch(tf.data.AUTOTUNE)"],"metadata":{"id":"tYje2nhRsunK"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Train model"],"metadata":{"id":"kq1zK21D9Xpl"}},{"cell_type":"code","source":["model = keras.Sequential()\n","model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(270,480,3)))\n","model.add(layers.Conv2D(filters=16, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=2))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(layers.Conv2D(filters=32, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=2))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Conv2D(filters=48, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(layers.Conv2D(filters=48, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=2))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=2))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(layers.Conv2D(filters=64, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","model.add(BatchNormalization())\n","model.add(layers.MaxPooling2D(pool_size=2))\n","model.add(layers.Dropout(0.2))\n","model.add(layers.Flatten())\n","model.add(layers.Dense(12, activation=\"relu\"))\n","model.add(layers.Dense(12, activation=\"relu\"))\n","model.add(layers.Dense(4))\n","\n","model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), \n","              loss=tf.keras.losses.MeanAbsoluteError(), \n","              metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","# model.summary()"],"metadata":{"id":"LQ08ZeGxVmIa"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["history = model.fit(ds_train, epochs=20, validation_data=ds_validate)"],"metadata":{"id":"R1SgFhGdSG-1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Nowa sekcja"],"metadata":{"id":"8QGVQzp8enNS"}},{"cell_type":"markdown","source":["Showing loss function chart"],"metadata":{"id":"7TT79k0f2TVT"}},{"cell_type":"code","source":["print(history.history.keys())\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'validation'], loc='upper left')\n","plt.show()"],"metadata":{"id":"iVJBUkf_41Yy"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Show prediction"],"metadata":{"id":"3gCoKUVtyB5m"}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import matplotlib.patches as patches\n","\n","imgs = ds_validate.as_numpy_iterator().next()\n","pred = model.predict(imgs[0])\n","idx = 0\n","\n","def convert(xy2):\n","    rect_y = xy2[0]*480\n","    rect_x = xy2[1]*480\n","    rect_yy = xy2[2]*480\n","    rect_xx = xy2[3]*480\n","    return rect_x, rect_y, rect_xx-rect_x, rect_yy-rect_y\n","\n","_, ax = plt.subplots()\n","ax.imshow(imgs[0][idx])\n","\n","x, y, w, h = convert(imgs[1][idx])\n","rect_true = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='b', facecolor='none')\n","ax.add_patch(rect_true)\n","\n","x, y, w, h = convert(pred[idx])\n","rect_pred = patches.Rectangle((x, y), w, h, linewidth=2, edgecolor='r', facecolor='none')\n","ax.add_patch(rect_pred)\n","\n","plt.show()"],"metadata":{"id":"iuKaAc49sfts"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# path = '/content/drive/MyDrive/example_img.jpeg'\n","\n","# image_open = open(path, 'rb')\n","# read_image = image_open.read()\n","# image_decode = tf.image.decode_jpeg(read_image)\n","# test_image_array = tf.keras.preprocessing.image.img_to_array(image_decode)\n","# test_image_array = test_image_array/255.\n","# img = test_image_array.reshape(1, 270, 480, 3)\n","# coordinates = model.predict(img)\n","\n","# x_min, y_min, x_max, y_max = coordinates[0][0]*480, coordinates[0][1]*480, coordinates[0][2]*480, coordinates[0][3]*480\n","\n","# # Displaying\n","# tensor = test_image_array*255.\n","# arr = np.array(tensor, dtype=np.uint8)\n","# sh_im = Image.fromarray(arr)\n","# shape = ((x_min, y_min), (x_max, y_max))\n","# img_draw = ImageDraw.Draw(sh_im)\n","# img_draw.rectangle(shape, outline =\"red\", width=3)\n","# print(shape)\n","# display(sh_im)"],"metadata":{"id":"pJkKTHSIk5JG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.save(\"/content/drive/MyDrive/images/saved_model\")"],"metadata":{"id":"oWwND2Qfr35B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ksRWcKhHFHWM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# model = keras.models.load_model(\"/content/drive/MyDrive/images/saved_model\")"],"metadata":{"id":"ZhU5Nl8mhicS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Using keras autotuner with different layers"],"metadata":{"id":"QMyaqRpZtlrH"}},{"cell_type":"code","source":["#@title\n","# def model_builder(hp):\n","#   model = keras.Sequential()\n","#   filters1 = hp.Int('filters1', min_value=8, max_value=32, step=8)\n","#   model.add(layers.Conv2D(filters=filters1, kernel_size=3, padding=\"same\", activation=\"relu\", input_shape=(270,480,3)))\n","#   model.add(layers.Conv2D(filters=filters1, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.MaxPooling2D(pool_size=2))\n","#   model.add(layers.Dropout(0.2))\n","#   filters2 = hp.Int('filters2', min_value=8, max_value=32, step=8)\n","#   model.add(layers.Conv2D(filters=filters2, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.Conv2D(filters=filters2, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.MaxPooling2D(pool_size=2))\n","#   model.add(layers.Dropout(0.2))\n","#   filters3 = hp.Int('filters3', min_value=16, max_value=64, step=16)\n","#   model.add(layers.Conv2D(filters=filters3, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.Conv2D(filters=filters3, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.MaxPooling2D(pool_size=2))\n","#   model.add(layers.Dropout(0.2))\n","#   filters4 = hp.Int('filters4', min_value=16, max_value=64, step=16)\n","#   model.add(layers.Conv2D(filters=filters4, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.Conv2D(filters=filters4, kernel_size=3, padding=\"same\", activation=\"relu\"))\n","#   model.add(layers.MaxPooling2D(pool_size=2))\n","#   model.add(layers.Dropout(0.2))\n","\n","#   model.add(layers.Flatten())\n","#   dense = hp.Int('dense', min_value=8, max_value=16, step=4)\n","#   model.add(layers.Dense(dense, activation=\"relu\"))\n","#   model.add(layers.Dense(dense, activation=\"relu\"))\n","#   model.add(layers.Dense(4))\n","\n","#   model.compile(optimizer=tf.optimizers.Adam(learning_rate=1e-3), loss=tf.keras.losses.MeanAbsoluteError(), metrics=[tf.keras.metrics.MeanAbsoluteError()])\n","\n","#   return model\n","\n","# tuner = kt.Hyperband(model_builder, objective='loss', max_epochs=10, factor=3, overwrite=True)\n","# stop_early = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n","# tuner.search(ds_train, epochs=20, validation_data=ds_validate, callbacks=[stop_early])\n"],"metadata":{"id":"Zic33WOvDCo_","cellView":"form"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#@title\n","# tuner.results_summary()"],"metadata":{"id":"kehNQ75mT6Dj","cellView":"form"},"execution_count":null,"outputs":[]}]}